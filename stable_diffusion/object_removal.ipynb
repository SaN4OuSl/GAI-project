{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, YolosForObjectDetection, CLIPTokenizer\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "from PIL import Image\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load YOLO model for object detection\n",
    "processor = AutoImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "model = YolosForObjectDetection.from_pretrained(\"hustvl/yolos-tiny\").to(device)\n",
    "\n",
    "# Load Stable Diffusion Inpainting pipeline\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe.to(device)\n",
    "\n",
    "# Load tokenizer manually\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\", use_fast=True)\n",
    "pipe.tokenizer = tokenizer\n",
    "\n",
    "# Ensure height and width are divisible by 8\n",
    "def adjust_size(width, height):\n",
    "    return (width // 8) * 8, (height // 8) * 8\n",
    "\n",
    "# Load image function\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(\"Image not found! Check the file path.\")\n",
    "\n",
    "    print(\"Image loaded successfully.\")\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image_rgb, image\n",
    "\n",
    "selected_boxes = []\n",
    "object_boxes = []\n",
    "image_for_display = None\n",
    "\n",
    "# Mouse click event handler\n",
    "def select_object(event, x, y, flags, param):\n",
    "    global selected_boxes, object_boxes, image_for_display\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        for i, (x1, y1, x2, y2) in enumerate(object_boxes):\n",
    "            if x1 <= x <= x2 and y1 <= y <= y2:\n",
    "                selected_boxes.append(i)\n",
    "                print(f\"Selected object {i+1} for removal.\")\n",
    "\n",
    "        temp_image = image_for_display.copy()\n",
    "        for i in selected_boxes:\n",
    "            x1, y1, x2, y2 = object_boxes[i]\n",
    "            cv2.rectangle(temp_image, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
    "\n",
    "        cv2.imshow(\"Select Objects to Remove\", temp_image)\n",
    "        cv2.startWindowThread()\n",
    "\n",
    "# Object detection and selection with YOLO\n",
    "def yolo_object_detection(image_rgb, image, padding=4):\n",
    "    global object_boxes, image_for_display\n",
    "\n",
    "    inputs = processor(images=image_rgb, return_tensors=\"pt\").to(device)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    target_sizes = torch.tensor([image_rgb.shape[:2]], device=device)\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.5)[0]\n",
    "\n",
    "    object_boxes = [box.int().tolist() for box in results[\"boxes\"]]\n",
    "\n",
    "    # Draw bounding boxes on a copy of the image\n",
    "    image_for_display = image.copy()\n",
    "    for x1, y1, x2, y2 in object_boxes:\n",
    "        cv2.rectangle(image_for_display, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "    # Open window for selection\n",
    "    cv2.imshow(\"Select Objects to Remove\", image_for_display)\n",
    "    cv2.setMouseCallback(\"Select Objects to Remove\", select_object)\n",
    "    print(\"\\nClick on the objects you want to remove. Press 'Enter' when done.\")\n",
    "\n",
    "    # Wait until Enter key is pressed\n",
    "    while True:\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 13:\n",
    "            detected_image_path = os.path.join(\"detected_objects/\", f\"{image_name}\")\n",
    "            cv2.imwrite(detected_image_path, cv2.cvtColor(image_for_display, cv2.COLOR_RGBA2RGB))\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.waitKey(1)\n",
    "            break\n",
    "\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    for i in selected_boxes:\n",
    "        x1, y1, x2, y2 = object_boxes[i]\n",
    "\n",
    "        x1 = max(0, x1 - padding)\n",
    "        y1 = max(0, y1 - padding)\n",
    "        x2 = min(image.shape[1], x2 + padding)\n",
    "        y2 = min(image.shape[0], y2 + padding)\n",
    "\n",
    "        mask[y1:y2, x1:x2] = 255\n",
    "\n",
    "    return mask\n",
    "\n",
    "# Inpainting using Stable Diffusion\n",
    "def stable_diffusion_inpainting(image_rgb, mask):\n",
    "    # Ensure dimensions are divisible by 8\n",
    "    width, height = adjust_size(image_rgb.shape[1], image_rgb.shape[0])\n",
    "\n",
    "    # Resize images while maintaining aspect ratio\n",
    "    image_pil = Image.fromarray(image_rgb).resize((width, height))\n",
    "    mask_pil = Image.fromarray(mask).resize((width, height))\n",
    "\n",
    "    # Run Stable Diffusion inpainting\n",
    "    inpainted_image = pipe(\n",
    "        prompt=(\n",
    "            \"Fill the missing background of the image naturally. \"\n",
    "            \"Maintain proper background lighting.\"\n",
    "            \"Do not introduce any new objects, patterns, or artificial elements.\"\n",
    "        ),\n",
    "        image=image_pil,\n",
    "        mask_image=mask_pil,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        num_inference_steps=100\n",
    "    ).images[0]\n",
    "\n",
    "    # Convert result to NumPy array\n",
    "    inpainted_array = np.array(inpainted_image)\n",
    "\n",
    "    # Resize inpainted image & mask back to original size\n",
    "    inpainted_array_resized = cv2.resize(inpainted_array, (image_rgb.shape[1], image_rgb.shape[0]), interpolation=cv2.INTER_LANCZOS4)\n",
    "    mask_resized = cv2.resize(mask, (image_rgb.shape[1], image_rgb.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Blend the inpainted result only in masked areas\n",
    "    final_result = image_rgb.copy()\n",
    "    final_result[mask_resized > 0] = inpainted_array_resized[mask_resized > 0]\n",
    "\n",
    "    return final_result\n",
    "\n",
    "def blend_edges(original, inpainted, mask):\n",
    "    blurred_mask = cv2.GaussianBlur(mask.astype(np.float32), (15, 15), 0)\n",
    "    blended = original * (1 - blurred_mask[:, :, None] / 255) + inpainted * (blurred_mask[:, :, None] / 255)\n",
    "    return blended.astype(np.uint8)\n",
    "\n",
    "def save_results(mask, output_image, output_image_blended):\n",
    "    mask_pil = Image.fromarray(mask)\n",
    "    output_pil = Image.fromarray(output_image)\n",
    "    output_blended_pil = Image.fromarray(output_image_blended)\n",
    "\n",
    "    mask_pil.save(\"masks/\" + image_name)\n",
    "    output_pil.save(\"outputs/\" + image_name)\n",
    "    output_blended_pil.save(\"outputs_blended/\" + image_name)\n",
    "    print(\"Mask and output image saved successfully.\")\n",
    "\n",
    "image_name = \"field.jpg\"\n",
    "\n",
    "try:\n",
    "    image_rgb, image = load_image(\"../input_images/\" + image_name)\n",
    "    mask = yolo_object_detection(image_rgb.copy(), image.copy())\n",
    "    stable_diffused_result = stable_diffusion_inpainting(image_rgb, mask)\n",
    "    blended_result = blend_edges(image_rgb, stable_diffused_result, mask)\n",
    "    save_results(mask, stable_diffused_result, blended_result)\n",
    "\n",
    "\n",
    "    current_pid = os.getpid()\n",
    "    for proc in psutil.process_iter(attrs=['pid', 'name']):\n",
    "        try:\n",
    "            if \"python\" in proc.info['name'].lower() and proc.info['pid'] != current_pid:\n",
    "                os.kill(proc.info['pid'], 9)\n",
    "        except (psutil.NoSuchProcess, psutil.AccessDenied):\n",
    "            continue\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
